# üçå Analisador de Matura√ß√£o de Banana


Notas: 


-- O Windows pode reconhecer o execut√°vel como um arquivo malicioso, mas basta clicar em executar mesmo assim e t√° tudo certo. Vai ser executado<br>

-- O programa n√£o acerta 100% das vezes, alguns equ√≠vocos acontecem quando uma imagem tem muito verde por exemplo, j√° que a imagem √© analisada como um todo, o modelo prediz uma banana verde o que pode n√£o ser uma verdade. <br>
-- Tivemos problema de compatibilidade com bibliotecas, o principal foi tentar utilizar o pyintaller com o python 3.13, tivemos que voltar para o 3.10.
-- O programa n√£o valida se uma imagem cont√©m ou n√£o uma banana. O modelo foi treinado com imagens de bananas e digamos que para o "mundo" dele s√≥ existe bananas. <br>
-- O programa abrir√° uma tela de terminal antes de ser executado.<br>
-- O programa demora um pouco para ser executado devido √†s biblitecas utilizadas como o tensorflow.<br>
-- Colocamos uma limita√ß√£o de 20MB para o tamanho da imagem adicionada.<br>
-- Colocamos uma verifica√ß√£o de confian√ßa da predi√ß√£o que requer 60% para que seja considerada uma predi√ß√£o v√°lida.<br>


Este √© um projeto de Deep Learning e Vis√£o Computacional que utiliza uma **Rede Neural Convolucional (CNN)** para classificar o est√°gio de matura√ß√£o de bananas.

O aplicativo de desktop (GUI) permite que um usu√°rio fa√ßa o upload de uma imagem e receba uma classifica√ß√£o em tempo real, informando um dos quatro est√°gio de matura√ß√£o:

* **Class A** - Verde
* **Class B** - Parcialmente Madura
* **Class C** - Madura
* **Class D** - Passada
<br>
LINK DE V√çDEO TESTE SEM AUDIO

https://drive.google.com/file/d/18caospEZf7bDh_pC_T_jo-B8VEgjV8I-/view?usp=sharing

## Conceitos de Intelig√™ncia Artificial utilizados

Este projeto √© um exemplo cl√°ssico de um *pipeline* completo de IA: **treinamento** (no `train_model.py`) e **infer√™ncia** (no `app.py`).

### 1. Rede Neural Convolucional (CNN)
O cora√ß√£o deste projeto √© uma CNN, um tipo de IA especializado em entender imagens. No `train_model.py`, n√≥s constru√≠mos essa rede "do zero". Ela aprende a identificar padr√µes visuais (como cor, textura e manchas) associados a cada est√°gio de matura√ß√£o.

### 2. Classifica√ß√£o de Imagem
A tarefa de IA sendo executada √© a **classifica√ß√£o de imagem**. O modelo √© treinado em milhares de imagens para "for√ßar" uma nova imagem em uma das 4 categorias (classes) que ele conhece.

### 3. Logits e Softmax
O modelo √© treinado com a perda `loss=...SparseCategoricalCrossentropy(from_logits=True)`. Isso significa que a sa√≠da bruta do modelo (`predictions`) n√£o s√£o probabilidades, mas sim n√∫meros brutos chamados **logits**.
No `app.py`, aplicamos `tf.nn.softmax(predictions[0])` para converter esses logits em um vetor de probabilidades (por exemplo: `[0.1, 0.05, 0.8, 0.05]`), onde cada n√∫mero representa a "confian√ßa" do modelo para uma classe, e a soma de todos √© 1.0 (ou 100%).

### 4. Infer√™ncia e Predi√ß√£o
O processo no `app.py` √© a **infer√™ncia**. N√≥s pegamos a probabilidade mais alta usando `np.argmax(score)` para determinar a classe vencedora e `np.max(score)` para obter o n√≠vel de confian√ßa dessa previs√£o.

---

## Conceitos de Computa√ß√£o Visual utilizados

Antes que a IA possa "ver" a imagem, ela precisa ser formatada corretamente. Este √© o trabalho da Computa√ß√£o Visual.

### No Treinamento (`train_model.py`)

1.  **Carregamento de Dados (`image_dataset_from_directory`)**: Esta fun√ß√£o varre as subpastas (`Class A`, `Class B`, etc.) e automaticamente rotula as imagens com base no nome da pasta em que est√£o.
2.  **Redimensionamento (`image_size=(180, 180)`)**: Padroniza todas as imagens de treino para `180x180` pixels.
3.  **Normaliza√ß√£o (`Rescaling(1./255)`)**: Converte os valores de pixel de [0-255] para [0.0-1.0]. Isso √© crucial para que a rede neural aprenda de forma eficiente.
4.  **Aumento de Dados (Data Augmentation)**:
    * `RandomFlip`, `RandomRotation`, `RandomZoom`: Esta √© uma t√©cnica poderosa. A cada √©poca de treinamento, o modelo "v√™" vers√µes ligeiramente diferentes das mesmas imagens (giradas, com zoom). Isso o ensina a ser mais robusto e evita que ele "decore" as imagens de treino (**overfitting**).

### Na Infer√™ncia (`app.py`)

Quando o usu√°rio faz o upload de uma imagem, um *pipeline* de CV semelhante √© aplicado para garantir que a imagem seja id√™ntica ao que o modelo espera:

1.  **Convers√£o de Espa√ßo de Cor (`.convert('RGB')`)**: Garante que imagens em tons de cinza ou com transpar√™ncia (PNG) sejam convertidas para o formato RGB de 3 canais que o modelo espera.
2.  **Redimensionamento (`.resize(MODEL_IMG_SIZE)`)**: Redimensiona a imagem do usu√°rio (que pode ter qualquer tamanho) para exatamente `(180, 180)`.
3.  **Convers√£o para Array (`img_to_array`)**: Converte a imagem de um objeto PIL para uma matriz NumPy (`(180, 180, 3)`) que o TensorFlow entende.
4.  **Expans√£o de Lote (`expand_dims`)**: Transforma a matriz em `(1, 180, 180, 3)`, criando um "lote de 1 imagem", que √© o formato de entrada que o modelo espera.

---

## Como o Projeto Funciona

O projeto √© dividido em dois scripts principais: a "f√°brica" (`train_model.py`) e o "produto final" (`app.py`).

### 1. `train_model.py` (A "F√°brica de C√©rebros")

Este script √© executado uma vez para criar o arquivo do modelo.

1.  **Carregamento:** Carrega as imagens das pastas `dataset/Real Dataset/train` e `dataset/Real Dataset/validation`.
2.  **Arquitetura (A Receita da CNN):**
    * **Blocos Convolucionais (Conv2D + MaxPooling2D):** O "sistema visual" do modelo. As camadas `Conv2D` atuam como filtros que aprendem a detectar caracter√≠sticas (bordas, curvas, cores, texturas). As camadas `MaxPooling2D` reduzem o tamanho da imagem, focando nas caracter√≠sticas mais importantes. A profundidade dos filtros aumenta (32 -> 64 -> 128 -> 256) para aprender padr√µes cada vez mais complexos.
    * **Flatten:** "Achata" os mapas de caracter√≠sticas 2D em um √∫nico vetor longo 1D.
    * **Camadas Densas (Dense):** O "c√©rebro" de classifica√ß√£o.
        * `Dense(512)`: Uma camada oculta que aprende a combinar as caracter√≠sticas visuais para tomar uma decis√£o.
        * `Dropout(0.5)`: Uma t√©cnica de regulariza√ß√£o que "desliga" aleatoriamente 50% dos neur√¥nios durante o treino para evitar overfitting.
        * `Dense(num_classes)`: A camada de sa√≠da final, com um neur√¥nio para cada classe.
3.  **Compila√ß√£o:** Prepara o modelo para o treino, definindo:
    * `optimizer='adam'`: O algoritmo que ajusta os pesos do modelo.
    * `loss='SparseCategoricalCrossentropy(from_logits=True)'`: A fun√ß√£o matem√°tica que mede o qu√£o "errada" est√° a previs√£o do modelo.
4.  **Treinamento (`model.fit`):**
    * O modelo "olha" para os lotes de imagens de `train_ds` repetidamente (10 `epochs`).
    * A cada √©poca, ele se valida contra o `val_ds` (dados que nunca viu).
    * `EarlyStopping`: Um "vigia" inteligente. Ele monitora a perda de valida√ß√£o (`val_loss`). Se a performance parar de melhorar por 5 √©pocas, o treino √© interrompido automaticamente, e os melhores pesos s√£o restaurados (`restore_best_weights=True`).
5.  **Salvamento:**
    * `model.save('banana_classifier_model.h5')`: Salva o "c√©rebro" treinado (arquitetura + pesos) em um √∫nico arquivo.
    * `class_names.txt`: Salva a lista de nomes das classes na ordem correta (ex: `['Class A', 'Class B', ...]`).

### 2. `app.py` (O Aplicativo para o Usu√°rio)

Este script usa os arquivos gerados pelo `train_model.py`.

1.  **Constantes e Carregamento (In√≠cio)**
    * `MODEL_IMG_SIZE = (180, 180)`: A constante mais importante. Garante que o app use o mesmo tamanho de imagem do treino.
    * `resource_path`: Uma fun√ß√£o vital para o **PyInstaller**. Garante que o app encontre seus arquivos (`.h5`, `.txt`), esteja ele rodando como `.py` ou `.exe`.
    * `tf.keras.models.load_model(MODEL_PATH)`: Carrega o "c√©rebro" (`.h5`) na mem√≥ria.
    * O app tamb√©m carrega o `class_names.txt` para traduzir o √≠ndice da previs√£o (ex: `2`) para um nome leg√≠vel (ex: `Class C`).

2.  **Interface Gr√°fica (`App` class)**
    * Usa `customtkinter` para criar uma janela moderna.
    * O bot√£o "Carregar Imagem" chama a fun√ß√£o `open_image_file`.

3.  **Fluxo de Execu√ß√£o (`open_image_file`)**
    * O usu√°rio seleciona um arquivo.
    * **Valida√ß√£o 1 (Tamanho):** O tamanho do arquivo (`os.path.getsize`) √© verificado contra `MAX_FILE_SIZE`.
    * **Valida√ß√£o 2 (Tipo):** O app tenta abrir a imagem (`Image.open`). Se falhar (ex: √© um `.txt`), o `UnidentifiedImageError` √© capturado.
    * A miniatura √© criada e exibida.
    * A imagem completa √© enviada para `predict_image`.

4.  **Fluxo de Predi√ß√£o (`predict_image`)**
    * A imagem passa pelo *pipeline* de pr√©-processamento de CV (RGB -> Resize -> Array -> Batch).
    * `model.predict()` √© chamado.
    * Os *logits* s√£o convertidos em probabilidades (`softmax`).
    * O resultado final (descri√ß√£o e confian√ßa) √© formatado e retornado para a UI.

---

## Como fazer todo o processo de treinamento e gera√ß√£o do execut√°vel

### Passo 1: Configurar o Ambiente

1.  **Instale o Python**: Baixe e instale o **Python 3.10** ou **3.11** (vers√µes est√°veis para este projeto). Marque **"Add Python to PATH"** durante a instala√ß√£o.
2.  **Crie a Pasta do Projeto**: Crie uma pasta (ex: `C:\Projetos\analyser`).
3.  **Abra o Prompt de Comando (CMD)** e navegue at√© sua pasta:
    ```bash
    cd C:\Projetos\analyser
    ```
4.  **Crie e Ative um Ambiente Virtual**:
    ```bash
    python -m venv venv
    venv\Scripts\activate
    ```
5.  **Instale as Bibliotecas**:
    ```bash
    pip install tensorflow customtkinter Pillow pyinstaller kagglehub
    ```

### Passo 2: Baixar o Dataset

1.  Na sua pasta (`analyser`), crie um arquivo chamado `download_data.py`.
2.  Cole o seguinte c√≥digo nele:
    ```python
    import kagglehub
    import os
    import zipfile
    
    dataset_name = "luischuquimarca/banana-ripeness"
    extract_path = "dataset" # Ir√° criar a pasta 'dataset'
    
    print(f"Baixando o dataset '{dataset_name}'...")
    path = kagglehub.dataset_download(dataset_name)
    print(f"Dataset baixado para: {path}")
    
    if not os.path.exists(extract_path):
        os.makedirs(extract_path)
    
    print(f"Extraindo arquivos para a pasta '{extract_path}'...")
    with zipfile.ZipFile(path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    
    print("Download e extra√ß√£o conclu√≠dos.")
    ```
3.  Execute o script **uma vez** (com o `(venv)` ativo):
    ```bash
    python download_data.py
    ```
    Ao final, voc√™ ter√° uma pasta `dataset` pronta para o treinamento.

### Passo 3: Treinar o Modelo

1.  Certifique-se de que os arquivos `train_model.py` e `app.py` disponibilizados neste reposit√≥rio est√£o na sua pasta `analyser`.
2.  Execute o script de treinamento:
    ```bash
    python train_model.py
    ```
3.  Este script ir√° demorar alguns minutos. Ao final, voc√™ ter√° dois novos arquivos essenciais na sua pasta:
    * `banana_classifier_model.h5` (O "c√©rebro" treinado)
    * `class_names.txt` (As "etiquetas" que o c√©rebro aprendeu)

### Passo 4: Gerar o Execut√°vel (`.exe`)

1.  Execute o comando do **PyInstaller** no seu terminal (ainda com o `(venv)` ativo):

    ```bash
    pyinstaller --onefile --windowed --add-data "banana_classifier_model.h5;." --add-data "class_names.txt;." app.py
    ```

3.  O processo pode levar alguns minutos.

### Passo 5: Testar

1.  Ap√≥s a conclus√£o, uma nova pasta `dist` ser√° criada.
2.  Dentro dela, voc√™ encontrar√° o `app.exe`.
3.  Este √© o programa final, s√≥ clicar e fazer os uploads das imagens de bananas.
